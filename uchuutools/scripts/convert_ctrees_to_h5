#!/usr/bin/env python

from uchuutools import convert_ctrees_to_h5
import argparse
helpmsg = "\nUsage Scenario 1:\n"
helpmsg += "-----------------\n"
helpmsg += "If you are converting the output of the standard "\
            "Consistent-Trees code, then \nplease provide the "\
            "full-path to the 'forests.list' and 'locations.dat'"\
            "(order is unimportant).\n\n"
helpmsg += "Usage Scenario 2:\n"
helpmsg += "-----------------\n"
helpmsg += "If you are converting the output of the parallel "\
            "Consistent-Trees code \nfrom the Uchuu collaboration, "\
            "then please provide all the tree filenames \nthat "\
            "you would like to convert (i.e., files ending with "\
            "'<prefix>.tree').\nThe names for relevant "\
            "'forests.list (<prefix>.forest)' and \n"\
            "'locations.dat (<prefix>.loc)' will be "\
            "automatically constructed.\n\n"
descr = "Convert ascii Consistent-Trees files into hdf5 "\
        "(optionally in MPI parallel)"

rank = 0
try:
    from mpi4py import MPI
    comm = MPI.COMM_WORLD
    rank = comm.rank
except ImportError:
    comm = None

parser = argparse.ArgumentParser(description=descr)
parser.add_argument('outputdir', metavar='<output directory>', type=str,
                    help='the output directory for the hdf5 file(s)')
parser.add_argument('output_filebase',
                    metavar='<output file prefix>',
                    type=str, default='forest',
                    help='the prefix to use for the output hdf file(s). '
                         'The fully qualified output filename is '
                         f'<outputdir>/<output_fileprefix>_{rank}.h5')
parser.add_argument("filenames", metavar="<CTrees filenames>",
                    type=str, nargs='+',
                    help="list of input (ascii) Consistent-Trees filenames (must provide at least one file to convert)")

prog_group = parser.add_mutually_exclusive_group()
prog_group.add_argument("-p", "--progressbar", dest='show_progressbar',
                        action="store_true", default=True,
                        help="display a progressbar on rank=0")
prog_group.add_argument("-np", "--no-progressbar", dest='show_progressbar',
                        action='store_false', help="disable the progressbar")

# Do you want to write each halo as a struct (i.e., ALL the
# properties of any given halo are written together, array of structures),
# or do you want to write out individual datasets for each of the
# halo properties (i.e., any given property of ALL halos are written
# together, structure of arrays -> default)
# write_halo_props_cont = True     # True -> structure of arrays,
#                                  # False-> array of structures
dset_group = parser.add_mutually_exclusive_group()
dset_group.add_argument("-m", "--multiple-dsets", dest='write_halo_props_cont',
                        action="store_true", default=True,
                        help="write a separate dataset for each halo property")
dset_group.add_argument("-s", "--single-dset", dest='write_halo_props_cont',
                        action="store_false", default=False,
                        help="write a single dataset containing all halo "
                        "properties")
try:
    args = parser.parse_args()
except SystemExit as e:
    print(helpmsg)
    raise e

convert_ctrees_to_h5(args.filenames, outputdir=args.outputdir,
                     output_filebase=args.output_filebase,
                     write_halo_props_cont=args.write_halo_props_cont,
                     comm=comm, show_progressbar=args.show_progressbar)
